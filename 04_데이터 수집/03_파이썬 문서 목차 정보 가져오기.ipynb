{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c994f41d-8414-49f2-951e-4bea03529de3",
   "metadata": {},
   "source": [
    "1. 원하는 데이터가 있는 사이트를 찾았는가? ok\n",
    "2. 페이지 소스 보기를 하였을 때 페이지 소스에 원하는 데이터가 있는가? ok\n",
    "3. 주소 분석이 가능한가? 해당사항 없음\n",
    "4. 끝나는 시점을 알 수 있는가? 해당사항 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83541c8d-ec09-4c49-96fd-8802e7f05a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가져온 html 데이터 분석을 위한 라이브러리\n",
    "import bs4\n",
    "# 웹 서버에 요청을 하기 위한 라이브러리\n",
    "import requests\n",
    "# 데이터 분석 라이브러리; 수집한 데이터를 저장하기 위해 사용하겠습니다\n",
    "import pandas as pd\n",
    "# 행렬 및 선형대수학을 위한 라이브러리; 결측치 값을 사용하기 위해 사용\n",
    "import numpy as np\n",
    "# 딜레이를 위해..\n",
    "import time\n",
    "# 컴퓨터나 os와 관련된 라이브러리; 파일 존재 여부를 확인하기 위해 사용\n",
    "import os\n",
    "# 주피터 노트북에서 출력된 내용을 지우기 위해 사용함\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cc7e76a-2824-4267-9176-4a5cc5208126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요청함수\n",
    "def getSource(site) :\n",
    "    \"\"\"\n",
    "        특정 웹 사이트에 접속하여 bs4 객체를 생성해 반환한다.\n",
    "\n",
    "        site \n",
    "            요청할 페이지의 주소\n",
    "\n",
    "        return 값\n",
    "            html 소스가 담겨져 있는 bs4 객체\n",
    "    \"\"\"\n",
    "\n",
    "    # 해더 정보 설정\n",
    "    # user-agent : 웹 브라우저가 서버로 보내는 문자열이고 서버는 이를 통해 브라우저 정보나 컴퓨터 정보를 파악한다.\n",
    "    # 일부 사이트에는 user-agent가 전달되지 않으면 데이터를 전달하지 않는 경우도 있다.\n",
    "    # 이에 user-agent를 셋팅하여 요청한 도구가 python 코드를 통한 것이 아닌 일반 웹브라우저를 통해 요청한 것처럼 속일 수 있다.\n",
    "    # https://m.avalon.co.kr/check.html 에서 user-agent 확인이 가능함. \n",
    "    header_info = {\n",
    "        'User-Agent' : 'Mozilla/5.0(Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    # 요청한다.\n",
    "    response = requests.get(site, headers=header_info)\n",
    "    # bs4 객체를 생성한다\n",
    "    soup = bs4.BeautifulSoup(response.text, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58237a33-bc78-4953-b11c-f9e862012849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 페이지의 데이터를 수집해 저장하는 함수\n",
    "def getData(soup, file_name) :\n",
    "    \"\"\"\n",
    "        한 페이지의 데이터를 수집해 파일에 저장하는 함수\n",
    "\n",
    "        soup\n",
    "            HTML 데이터를 관리하는 bs4 객체\n",
    "\n",
    "        file_name\n",
    "            데이터를 저장할 파일 이름\n",
    "    \"\"\"\n",
    "    # 목록 전체 영역을 가져온다.\n",
    "    ul_tag = soup.select_one('#the-python-standard-library > div > ul')\n",
    "    # print(ul_tag)\n",
    "\n",
    "    # 하위에 있는 li 태그들을 가져온다.\n",
    "    li_tag_list = ul_tag.select('li > a')\n",
    "\n",
    "    data_dict = {\n",
    "        '제목' : [],\n",
    "        '링크주소' : [],\n",
    "    }\n",
    "\n",
    "    for li_tag in li_tag_list : \n",
    "        # print(li_tag)\n",
    "        # print(li_tag.text.strip())\n",
    "        # print(li_tag.attrs['href'])\n",
    "        # print(\"-\" * 30)\n",
    "        data_dict['제목'].append(li_tag.text.strip())\n",
    "        data_dict['링크주소'].append(li_tag.attrs['href'].strip())\n",
    "\n",
    "    # 데이터 프레임을 생성한다.\n",
    "    df1 = pd.DataFrame(data_dict)\n",
    "\n",
    "    df1.to_csv(file_name, encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8875617c-c9d3-46c1-b97e-b40b16c53090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요청할 페이지의 주소\n",
    "site = 'https://docs.python.org/3/library/index.html'\n",
    "# 페이지를 요청해서 가져온다.\n",
    "soup = getSource(site)\n",
    "# 데이터를 수집한다.\n",
    "getData(soup, 'data3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
